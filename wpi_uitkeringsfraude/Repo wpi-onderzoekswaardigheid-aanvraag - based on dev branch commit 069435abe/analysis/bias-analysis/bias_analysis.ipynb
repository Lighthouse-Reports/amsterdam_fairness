{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "To run the bias analysis for the current process, you need a dataset that contains the IC screenings. The easiest way to do this is to run `train_model.py` after adjusting the `handling_types` parameter in the `config.yml` to include: `[\"is_onderzoek_hh\", \"is_screening_hh\", \"is_screening_ic\"]`. Then the `BIAS_X_test.csv` and `BIAS_y_test.csv` will include everything. Since the model will also get retrained on the IC screenings, which we don't want, you should copy the two saved files to elsewhere, then revert the `config.yml` and retrain to get the original model back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "# To display BSNs fully\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wpi_onderzoekswaardigheid_aanvraag.project_paths import ARTIFACT_PATH, DATA_PATH, CONFIG_PATH, INFO_PATH\n",
    "from wpi_onderzoekswaardigheid_aanvraag.model.manage_model_info import load_feature_list\n",
    "from wpi_onderzoekswaardigheid_aanvraag.model.build_model import filter_application_handling\n",
    "from wpi_onderzoekswaardigheid_aanvraag.settings.settings import WPISettings\n",
    "from wpi_onderzoekswaardigheid_aanvraag.components import SocratesDienstPersoonJoin, SocratesAdresFeatures\n",
    "\n",
    "WPISettings.set_from_yaml(CONFIG_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bias_collection.bias_analyzer import BiasAnalyzer\n",
    "from fraude_preventie.datasources.dbutils import db_url_from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = ARTIFACT_PATH / \"model.pkl\"\n",
    "model_dict = joblib.load(model_file)\n",
    "_model = model_dict[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = _model[:-1]  # all but the last pipeline steps, hence all transformers, but not the model\n",
    "model = _model[-1]  # the actual model\n",
    "\n",
    "num_cols, cat_cols = load_feature_list()\n",
    "label = \"onderzoekswaardig\"\n",
    "X_test = pd.read_csv(DATA_PATH / \"BIAS_X_test.csv\")\n",
    "y_test = pd.read_csv(DATA_PATH / \"BIAS_y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the analysis input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we need to use X_test for this rather than the transformed data, because\n",
    "# to do the joins correctly we need some columns that are not in the transformed data\n",
    "# anymore.\n",
    "X_test_enriched = X_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_info = WPISettings.get_settings()[\"connections\"][\"basisinformatie_db\"];\n",
    "connection_info[\"options\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get from Postgresql DB - WPI dump\n",
    "- leeftijd (age)\n",
    "- nationaliteit (nationality)\n",
    "- geslacht (gender)\n",
    "- postcode\n",
    "\n",
    "Get from Postgresql DB - BRP dump\n",
    "- geboorteland (country of birth)\n",
    "- burgerlijke staat (civil status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add geslacht, nationaliteit, leeftijd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sql_query = \"\"\"with ref as (\n",
    "    select attribuut_waarde, attribuut_waarde_omschrijving\n",
    "    from wpi_hashed.socrates_ref\n",
    "    where attribuut = 'NATIONALITEIT1'\n",
    ")\n",
    "select subjectnr, dtopvoer, dtafvoer, dtgeboortegba, geslacht, nationaliteit1, attribuut_waarde_omschrijving as nationaliteit\n",
    "from wpi_hashed.socrates_persoon sp\n",
    "left join ref on sp.nationaliteit1 = ref.attribuut_waarde\"\"\"\n",
    "\n",
    "nationaliteit_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test_enriched = SocratesDienstPersoonJoin.join_dienst_persoon(X_test_enriched, nationaliteit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_enriched[\"leeftijd\"] = X_test_enriched[\"dtaanvraag\"].astype(\"datetime64\").dt.year - X_test_enriched[\"dtgeboortegba_persoon\"].astype(\"datetime64\").dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select attribuut_waarde, attribuut_waarde_omschrijving\n",
    "from wpi_hashed.socrates_ref\n",
    "where attribuut = 'NATIONALITEIT1'\n",
    "\"\"\"\n",
    "\n",
    "nationaliteit_mapping = pd.read_sql(sql_query, db_url_from_config(connection_info)).set_index(\"attribuut_waarde\")[\"attribuut_waarde_omschrijving\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wpi_onderzoekswaardigheid_aanvraag.preprocessing.clean import WPICleanTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select subjectnr, dtbegin, dteinde, dtopvoer, dtafvoer, postcodenum, geldig\n",
    "from wpi_hashed.socrates_adres sp\n",
    "\"\"\"\n",
    "\n",
    "postcode_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_df = WPICleanTransformer(\n",
    "    remove_invalidated_data=True,\n",
    "    col_type_mapping=[\n",
    "        (\"dtbegin\", \"datetime64\"),\n",
    "        (\"dteinde\", \"datetime64\"),\n",
    "        (\"dtopvoer\", \"datetime64\"),\n",
    "        (\"dtafvoer\", \"datetime64\"),\n",
    "    ],\n",
    "    fix_no_end_date=[\"dteinde\"],\n",
    ").transform(postcode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = SocratesAdresFeatures.join_applications_adres(X_test_enriched, postcode_df)\n",
    "df_tmp = SocratesAdresFeatures.filter_adres_relevant_to_application(df_tmp)\n",
    "X_test_enriched = df_tmp.sort_values(\"dtbegin_adres\").drop_duplicates(\n",
    "    \"application_dienstnr\", keep=\"last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BSN from WPI data in order to join with BRP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select subjectnr, bsn, dtopvoer\n",
    "from wpi_hashed.socrates_persoon\n",
    "where bsn != 'eb763221a7e6f47e6c8f5062f8fd1ad18a95264c7366928afc8ed92e7d1917a3'\n",
    "\"\"\"\n",
    "\n",
    "bsn_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter BSNs on the subject numbers that we need, then remove duplicates.\n",
    "relevant_bsns = bsn_df[bsn_df[\"subjectnr\"].isin(X_test_enriched[\"subjectnr\"].unique())].drop_duplicates()\n",
    "shape_step1 = relevant_bsns.shape\n",
    "relevant_bsns = relevant_bsns.sort_values(\"dtopvoer\", ascending=True).drop_duplicates(\"subjectnr\", keep=\"last\")\n",
    "shape_step2 = relevant_bsns.shape\n",
    "\n",
    "if shape_step1 != shape_step2:\n",
    "    print(\"Warning: There were people with more than 1 BSN, for them the last known BSN is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = X_test_enriched.shape\n",
    "X_test_enriched = X_test_enriched.merge(relevant_bsns, how=\"left\", on=\"subjectnr\")\n",
    "new_shape = X_test_enriched.shape\n",
    "\n",
    "# Assert that the number of rows didn't change. If it did, we have subject numbers with more than 1 BSN!\n",
    "assert old_shape[0] == new_shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add geboorteland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select bsn, geboorteland\n",
    "from bias_analyse_wpi.brp_rapport\n",
    "\"\"\"\n",
    "\n",
    "geboorteland_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geboorteland_df = geboorteland_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = X_test_enriched.shape\n",
    "X_test_enriched = X_test_enriched.merge(geboorteland_df, how=\"left\", on=\"bsn\")\n",
    "new_shape = X_test_enriched.shape\n",
    "\n",
    "# Assert that the number of rows didn't change. If it did, we have BSNs with more than 1 geboorteland.\n",
    "assert old_shape[0] == new_shape[0]\n",
    "\n",
    "X_test_enriched[\"geboorteland\"] = pd.Categorical(X_test_enriched['geboorteland'])\n",
    "X_test_enriched[\"geboorteland_code\"] = X_test_enriched['geboorteland'].cat.codes\n",
    "\n",
    "geboorteland_mapping = dict(enumerate(X_test_enriched[\"geboorteland\"].cat.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add burgerlijke staat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H = huwelijk\n",
    "- P = geregistreerd partnerschap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select bsn, soort_verbintenis, datum_sluiting, datum_ontbinding\n",
    "from bias_analyse_wpi.brp_rapport\n",
    "\"\"\"\n",
    "\n",
    "burg_staat_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "burg_staat_df[\"datum_sluiting\"] = pd.to_datetime(burg_staat_df[\"datum_sluiting\"].replace(dt.date(1001, 1, 1), pd.Timestamp.min))\n",
    "burg_staat_df[\"datum_ontbinding\"] = pd.to_datetime(burg_staat_df[\"datum_ontbinding\"].replace(dt.date(1001, 1, 1), pd.Timestamp.min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_civil_status_at_date(civil_status_df, bsn, date):\n",
    "    df = civil_status_df[civil_status_df[\"bsn\"] == bsn]\n",
    "    df = df[df[\"datum_sluiting\"].isna() | (df[\"datum_sluiting\"] <= date)]\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        logger.warning(f\"BSN not found in dataframe, assuming that civil status is 'single': {bsn}\")\n",
    "        return \"single\"\n",
    "    \n",
    "    # `datum_sluiting` is always filled in our dump for marriage/partnership (H/P).\n",
    "    # So if all NaN, then there no partnership/marriage in the BRP.\n",
    "    if df[\"datum_sluiting\"].isna().mean() == 1:\n",
    "        civil_status = \"single\"\n",
    "        \n",
    "    else:            \n",
    "        # Check if last available partnership/marriage is still current.\n",
    "        df = df.sort_values(\"datum_sluiting\", ascending=False).drop_duplicates(subset=[\"bsn\"], keep=\"first\")\n",
    "        \n",
    "        if df[\"datum_ontbinding\"].isna().mean() == 1:\n",
    "            civil_status = \"partnership_or_married\"\n",
    "            \n",
    "        else:\n",
    "            civil_status = \"separated_or_divorced_or_widowed\"\n",
    "    \n",
    "    return civil_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_enriched[\"burgerlijke_staat\"] = [get_civil_status_at_date(burg_staat_df, row[\"bsn\"], row[\"dtaanvraag\"]) for i, row in X_test_enriched.iterrows()]\n",
    "\n",
    "X_test_enriched[\"burgerlijke_staat\"] = pd.Categorical(X_test_enriched['burgerlijke_staat'])\n",
    "X_test_enriched[\"burgerlijke_staat_code\"] = X_test_enriched['burgerlijke_staat'].cat.codes\n",
    "\n",
    "burgerlijke_staat_mapping = dict(enumerate(X_test_enriched[\"burgerlijke_staat\"].cat.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_enriched = X_test_enriched.rename(columns={\n",
    "    \"nationaliteit1_persoon\": \"nationaliteit_code\",\n",
    "    \"postcodenum_adres\": \"postcodenum\",\n",
    "    \"geslacht_persoon\": \"geslacht\",\n",
    "})\n",
    "\n",
    "external_bias_columns = [\n",
    "    \"geslacht\",\n",
    "    \"leeftijd\",\n",
    "    \"nationaliteit_code\",\n",
    "    \"postcodenum\",\n",
    "    \"geboorteland_code\",\n",
    "    \"burgerlijke_staat_code\",\n",
    "]\n",
    "\n",
    "data_to_analyze = transformations.transform(X_test)\n",
    "data_to_analyze[label] = y_test[label].replace({True: 1, False: 0})\n",
    "data_to_analyze.index = X_test[\"application_dienstnr\"]\n",
    "\n",
    "data_to_analyze = data_to_analyze.merge(X_test_enriched.set_index(\"application_dienstnr\")[external_bias_columns], left_index=True, right_index=True)\n",
    "data_to_analyze = data_to_analyze.dropna()\n",
    "\n",
    "data_to_analyze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_to_check = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 = unknown\n",
    "- 1 = male\n",
    "- 2 = female\n",
    "\n",
    "Note that we only compare male vs. female, because we don't have enough samples with unknown gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"geslacht\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_analyze = data_to_analyze[data_to_analyze[\"geslacht\"] != 0]\n",
    "features_to_check[\"geslacht\"] = [[1], [2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"leeftijd\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"leeftijd\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"leeftijd_split1\"] = [0, 100, 40, 1]\n",
    "features_to_check[\"leeftijd_split2\"] = [0, 100, 50, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"west-nonwest-nationalities.json\", 'r') as j:\n",
    "    west_nonwest_nationalities = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for code, nationality in zip(data_to_analyze[\"nationaliteit_code\"].value_counts().iteritems(), data_to_analyze[\"nationaliteit_code\"].map(nationaliteit_mapping).value_counts().iteritems()):\n",
    "    print(f\"Count: {nationality[1]:<5} Code: {int(code[0]):<5} {nationality[0]:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_mapping = {v: k for k,v in nationaliteit_mapping.items()}\n",
    "west_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_nationalities[\"west\"]]\n",
    "nonwest_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_nationalities[\"nonwest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze_no_unknown_nationality = data_to_analyze[data_to_analyze[\"nationaliteit_code\"] != 0]\n",
    "# Check that all nationality codes got assigned to west/nonwest except 0 = unknown.\n",
    "assert (data_to_analyze_no_unknown_nationality[\"nationaliteit_code\"].isin(west_codes) | data_to_analyze_no_unknown_nationality[\"nationaliteit_code\"].isin(nonwest_codes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"nationaliteit_code_split1\"] = [west_codes, nonwest_codes]  # West vs. non-west\n",
    "features_to_check[\"nationaliteit_code_split2\"] = [\n",
    "    [1], \n",
    "    [n for n in data_to_analyze[\"nationaliteit_code\"] if n not in [0, 1]]  # Dutch vs. non-Dutch\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"west-nonwest-countries.json\", 'r') as j:\n",
    "    west_nonwest_countries = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for code, country in zip(data_to_analyze[\"geboorteland_code\"].value_counts().iteritems(), data_to_analyze[\"geboorteland_code\"].map(geboorteland_mapping).value_counts().iteritems()):\n",
    "    print(f\"Count: {country[1]:<5} Code: {int(code[0]):<5} {country[0]:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_mapping = {v: k for k,v in geboorteland_mapping.items()}\n",
    "west_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_countries[\"west\"]]\n",
    "nonwest_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_countries[\"nonwest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all country codes got assigned to west/nonwest.\n",
    "assert (data_to_analyze[\"geboorteland_code\"].isin(west_codes) | data_to_analyze[\"geboorteland_code\"].isin(nonwest_codes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"geboorteland_code_split1\"] = [west_codes, nonwest_codes]  # West vs. non-west\n",
    "features_to_check[\"geboorteland_code_split2\"] = [\n",
    "    [39], \n",
    "    [n for n in data_to_analyze[\"geboorteland_code\"] if n != 39]  # Dutch vs. non-Dutch\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Civil status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code, burg_staat in zip(data_to_analyze[\"burgerlijke_staat_code\"].value_counts().iteritems(), data_to_analyze[\"burgerlijke_staat_code\"].map(burgerlijke_staat_mapping).value_counts().iteritems()):\n",
    "    print(f\"Count: {burg_staat[1]:<5} Code: {int(code[0]):<5} {burg_staat[0]:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv = [2]  # single\n",
    "unpriv = [0, 1]\n",
    "features_to_check[\"burgerlijke_staat_code\"] = [priv, unpriv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: deelnames_started_percentage_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"deelnames_started_percentage_last_year\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"deelnames_started_percentage_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"deelnames_started_percentage_last_year_equals_zero\"] = (data_to_analyze[\"deelnames_started_percentage_last_year\"] == 0)*1\n",
    "data_to_analyze[\"deelnames_started_percentage_last_year_equals_one\"] = (data_to_analyze[\"deelnames_started_percentage_last_year\"] == 1)*1\n",
    "\n",
    "# This means: People who started nothing last year (incl. those who weren't in the system last year) vs. people who started something or everything.\n",
    "features_to_check[\"deelnames_started_percentage_last_year_equals_zero\"] = [\n",
    "    [0], [1]\n",
    "]\n",
    "# This means: People who started everything last year vs. those who didn't start everything or who weren't in the system last year.\n",
    "features_to_check[\"deelnames_started_percentage_last_year_equals_one\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: at_least_one_address_in_amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"at_least_one_address_in_amsterdam\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"at_least_one_address_in_amsterdam\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: active_address_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"active_address_count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"active_address_count\"] = [\n",
    "    [1], [2, 3]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: days_since_last_relocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"days_since_last_relocation\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"days_since_last_relocation\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"days_since_last_relocation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_value = 365\n",
    "features_to_check[\"days_since_last_relocation\"] = [\n",
    "    [n for n in data_to_analyze[\"days_since_last_relocation\"].unique() if n > split_value],  # Same address for a long time\n",
    "    [n for n in data_to_analyze[\"days_since_last_relocation\"].unique() if n <= split_value]  # Moved in the past year\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: days_since_last_dienst_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"days_since_last_dienst_end\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"days_since_last_dienst_end_split1\"] = [\n",
    "    [99999],  # No dienst last year\n",
    "    [n for n in data_to_analyze[\"days_since_last_dienst_end\"].unique() if n != 99999]  # Had a dienst last year\n",
    "]\n",
    "\n",
    "split_value = 60\n",
    "features_to_check[\"days_since_last_dienst_end_split2\"] = [\n",
    "    [n for n in data_to_analyze[\"days_since_last_dienst_end\"].unique() if n > split_value],  # Dienst longer than 60 days ago\n",
    "    [n for n in data_to_analyze[\"days_since_last_dienst_end\"].unique() if n <= split_value]  # Dienst within last 60 days\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: has_medebewoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"has_medebewoner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"has_medebewoner\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: avg_percentage_maatregel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"avg_percentage_maatregel\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we have too few samples to say anything meaningful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: total_vermogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"total_vermogen\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"total_vermogen\"].hist(bins=300, figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_value = 0\n",
    "features_to_check[\"total_vermogen_split1\"] = [ \n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n >= split_value],  # Greater than or equal to zero wealth\n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n < split_value]    # Negative wealth\n",
    "]\n",
    "\n",
    "split_value = 0\n",
    "features_to_check[\"total_vermogen_split2\"] = [ \n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n > split_value],  # Positive wealth\n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n < split_value]    # Negative wealth\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: afspraken_no_show_count_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"afspraken_no_show_count_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"afspraken_no_show_count_last_year\"] = [\n",
    "    [0], [1, 2, 3]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: has_partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"has_partner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"has_partner\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: sum_inkomen_bruto_was_mean_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"sum_inkomen_bruto_was_mean_imputed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"sum_inkomen_bruto_was_mean_imputed\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: applied_for_same_product_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"applied_for_same_product_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"applied_for_same_product_last_year\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: received_same_product_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"received_same_product_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"received_same_product_last_year\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: afspraken_no_contact_count_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"afspraken_no_contact_count_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we have too few samples to say anything meaningful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: sum_inkomen_bruto_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"sum_inkomen_bruto_value\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"sum_inkomen_bruto_value\"] = [ \n",
    "    [0],  # No income\n",
    "    [n for n in data_to_analyze[\"sum_inkomen_bruto_value\"].unique() if n > 0]    # Has non-zero income\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "external_variables = external_bias_columns + [\n",
    "    \"deelnames_started_percentage_last_year_equals_zero\", \n",
    "    \"deelnames_started_percentage_last_year_equals_one\"\n",
    "]\n",
    "\n",
    "BiasAnalyzer(\n",
    "    [\n",
    "        \"false_positive_rate_difference\",\n",
    "        \"false_positive_rate_ratio\",\n",
    "        \"false_positive_group_size_difference\",\n",
    "        \"false_positive_group_size_ratio\",\n",
    "    ]\n",
    ").analyze_features(\n",
    "    data_to_analyze=data_to_analyze,\n",
    "    model=_model.named_steps[\"clf\"].best_estimator_,\n",
    "    sensitive_features=features_to_check,\n",
    "    outpath=Path(INFO_PATH) / \"bias_report\",\n",
    "#     thresholds=np.arange(0.4, 0.6, 0.01),\n",
    "    label_column_name=label,\n",
    "    external_variables=external_variables,\n",
    "#     print_metric_explanations=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(BiasAnalyzer.log_info_by_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run the stuff below\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- False discovery rate difference is positive (0.011), meaning that the female group is (barely) disadvantaged.\n",
    "- False positive rate difference is negative (-0.089), meaning that the male group is disadvantaged.\n",
    "- False positive/group size difference is negative (-0.054), meaning that the male group is disadvantaged.\n",
    "\n",
    "#### False discovery rate difference interpretation\n",
    "FDR male = 0.1\n",
    "Out of all the males we investigate, 10% are actually innocent.\n",
    "\n",
    "FDR female = 0.1 + 0.011 = 0.111\n",
    "Out of all the females we investigate, 11.1% are actually innocent.\n",
    "\n",
    "If we investigate a woman, she is 1.1 percentage points more likely to be innocent than a man we investigate.\n",
    "\n",
    "\n",
    "#### False positive rate difference interpretation\n",
    "FPR male = 0.1\n",
    "If you are an innocent male, then you have a 10% chance of being investigated anyway.\n",
    "\n",
    "FPR female = 0.1 - 0.089 = 0.011\n",
    "If you are an innocent female, then you have a 1.1% chance of being investigated anyway.\n",
    "\n",
    "The chance of being investigated as an innocent male is 8.9 percentage points higher than as an innocent female.\n",
    "\n",
    "\n",
    "#### False positive/group size difference interpretation\n",
    "FP/GS male = 0.089\n",
    "A random man has a 8.9% chance to be wrongly investigated.\n",
    "\n",
    "FP/GS female = 0.035\n",
    "A random woman has a 3.5% chance to be wrongly investigated.\n",
    "\n",
    "The chance of being wrongly investigated for a random man is 5.4 percentage points higher than for a random woman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[[\"geslacht\", \"onderzoekswaardig\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# Test\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.groupby(\"geslacht\")[\"onderzoekswaardig\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False positive/group size\n",
    "P(Y_hat=1, Y=0|group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_with_preds = analysis_df.copy()\n",
    "analysis_df_with_preds[\"y_pred\"] = model.predict_proba(analysis_df.drop([\"geslacht\", \"onderzoekswaardig\"], axis=1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df = analysis_df_with_preds[analysis_df_with_preds[\"geslacht\"]==1]\n",
    "male_fp_group_size = ((male_df[\"y_pred\"] > 0.5) & (male_df[\"onderzoekswaardig\"] == 0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df = analysis_df_with_preds[analysis_df_with_preds[\"geslacht\"]==2]\n",
    "female_fp_group_size = ((female_df[\"y_pred\"] > 0.5) & (female_df[\"onderzoekswaardig\"] == 0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Male: {male_fp_group_size:.3f}\")\n",
    "print(f\"Female: {female_fp_group_size:.3f}\")\n",
    "print(f\"False positive/group size difference: {female_fp_group_size - male_fp_group_size:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
