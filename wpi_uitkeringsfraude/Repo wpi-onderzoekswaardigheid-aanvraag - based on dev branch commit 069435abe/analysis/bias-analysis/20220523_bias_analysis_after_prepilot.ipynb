{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "# To display BSNs fully\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "\n",
    "# For convenience\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wpi_onderzoekswaardigheid_aanvraag.project_paths import ARTIFACT_PATH, DATA_PATH, CONFIG_PATH, INFO_PATH\n",
    "from wpi_onderzoekswaardigheid_aanvraag.model.manage_model_info import load_feature_list\n",
    "from wpi_onderzoekswaardigheid_aanvraag.model.build_model import filter_application_handling\n",
    "from wpi_onderzoekswaardigheid_aanvraag.settings.settings import WPISettings\n",
    "from wpi_onderzoekswaardigheid_aanvraag.components import SocratesDienstPersoonJoin, SocratesAdresFeatures\n",
    "from wpi_onderzoekswaardigheid_aanvraag.scorer import Scorer\n",
    "\n",
    "WPISettings.set_from_yaml(CONFIG_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bias_collection.bias_analyzer import BiasAnalyzer\n",
    "from fraude_preventie.datasources.dbutils import db_url_from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepilot_df = pd.read_csv(\"20220523_data_for_bias_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_for_prepilot = pd.read_csv(\"../tickets/WT9D-244-prepilot-scores/20220517_applications_to_investigate_for_prepilot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepilot_df[\"selected_for_prepilot\"] = prepilot_df[\"application_dienstnr\"].isin(selected_for_prepilot[\"Aanvraagnummer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = Path('20220523_model_used_in_prepilot.pkl')\n",
    "# model_file = ARTIFACT_PATH / \"model.pkl\"\n",
    "# ppl_file = ARTIFACT_PATH / \"pipeline.pkl\"\n",
    "\n",
    "model_dict = joblib.load(model_file)\n",
    "model = model_dict[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = model[:-1]  # all but the last pipeline steps, hence all transformers, but not the model\n",
    "clf = model[-1]  # the actual model\n",
    "\n",
    "num_cols, cat_cols = load_feature_list()\n",
    "label = \"onderzoekswaardig\"\n",
    "# X_test = pd.read_csv(DATA_PATH / \"BIAS_X_test.csv\")\n",
    "# y_test = pd.read_csv(DATA_PATH / \"BIAS_y_test.csv\")\n",
    "X_test = prepilot_df\n",
    "y_test = prepilot_df[\"onderzoekswaardig\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the analysis input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we need to use X_test for this rather than the transformed data, because\n",
    "# to do the joins correctly we need some columns that are not in the transformed data\n",
    "# anymore.\n",
    "X_test_enriched = X_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_info = WPISettings.get_settings()[\"connections\"][\"basisinformatie_db\"];\n",
    "connection_info[\"options\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get from Postgresql DB - WPI dump\n",
    "- leeftijd (age)\n",
    "- nationaliteit (nationality)\n",
    "- geslacht (gender)\n",
    "- postcode\n",
    "\n",
    "Get from Postgresql DB - BRP dump\n",
    "- geboorteland (country of birth)\n",
    "- burgerlijke staat (civil status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add  nationaliteit, leeftijd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sql_query = \"\"\"with ref as (\n",
    "    select attribuut_waarde, attribuut_waarde_omschrijving\n",
    "    from wpi_hashed.socrates_ref\n",
    "    where attribuut = 'NATIONALITEIT1'\n",
    ")\n",
    "select subjectnr, dtopvoer, dtafvoer, dtgeboortegba, nationaliteit1, attribuut_waarde_omschrijving as nationaliteit\n",
    "from wpi_hashed_v2.socrates_persoon sp\n",
    "left join ref on sp.nationaliteit1 = ref.attribuut_waarde\"\"\"\n",
    "\n",
    "nationaliteit_df = pd.read_sql(sql_query, db_url_from_config(connection_info))\n",
    "nationaliteit_df[\"geboortejaar\"] = nationaliteit_df[\"dtgeboortegba\"].astype(\"datetime64\").dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_enriched = SocratesDienstPersoonJoin.join_dienst_persoon(X_test_enriched, nationaliteit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_enriched[\"leeftijd\"] = X_test_enriched[\"dtaanvraag\"].astype(\"datetime64\").dt.year - X_test_enriched[\"geboortejaar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select attribuut_waarde, attribuut_waarde_omschrijving\n",
    "from wpi_hashed.socrates_ref\n",
    "where attribuut = 'NATIONALITEIT1'\n",
    "\"\"\"\n",
    "\n",
    "nationaliteit_mapping = pd.read_sql(sql_query, db_url_from_config(connection_info)).set_index(\"attribuut_waarde\")[\"attribuut_waarde_omschrijving\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wpi_onderzoekswaardigheid_aanvraag.preprocessing.clean import WPICleanTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select subjectnr, dtbegin, dteinde, dtopvoer, dtafvoer, postcodenum, geldig\n",
    "from wpi_hashed_v2.socrates_adres sp\n",
    "\"\"\"\n",
    "\n",
    "postcode_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_df = WPICleanTransformer(\n",
    "    remove_invalidated_data=True,\n",
    "    col_type_mapping=[\n",
    "        (\"dtbegin\", \"datetime64\"),\n",
    "        (\"dteinde\", \"datetime64\"),\n",
    "        (\"dtopvoer\", \"datetime64\"),\n",
    "        (\"dtafvoer\", \"datetime64\"),\n",
    "    ],\n",
    "    fix_no_end_date=[\"dteinde\"],\n",
    ").transform(postcode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = SocratesAdresFeatures.join_applications_adres(X_test_enriched, postcode_df)\n",
    "df_tmp = SocratesAdresFeatures.filter_adres_relevant_to_application(df_tmp)\n",
    "X_test_enriched = df_tmp.sort_values(\"dtbegin_adres\").drop_duplicates(\n",
    "    \"application_dienstnr\", keep=\"last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BSN from WPI data in order to join with BRP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select subjectnr, bsn, dtopvoer\n",
    "from wpi_hashed_v2.socrates_persoon\n",
    "where bsn != 'eb763221a7e6f47e6c8f5062f8fd1ad18a95264c7366928afc8ed92e7d1917a3'\n",
    "\"\"\"\n",
    "\n",
    "bsn_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter BSNs on the subject numbers that we need, then remove duplicates.\n",
    "relevant_bsns = bsn_df[bsn_df[\"subjectnr\"].isin(X_test_enriched[\"subjectnr\"].unique())].drop_duplicates()\n",
    "shape_step1 = relevant_bsns.shape\n",
    "relevant_bsns = relevant_bsns.sort_values(\"dtopvoer\", ascending=True).drop_duplicates(\"subjectnr\", keep=\"last\")\n",
    "shape_step2 = relevant_bsns.shape\n",
    "\n",
    "if shape_step1 != shape_step2:\n",
    "    print(\"Warning: There were people with more than 1 BSN, for them the last known BSN is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = X_test_enriched.shape\n",
    "X_test_enriched = X_test_enriched.merge(relevant_bsns, how=\"left\", on=\"subjectnr\")\n",
    "new_shape = X_test_enriched.shape\n",
    "\n",
    "# Assert that the number of rows didn't change. If it did, we have subject numbers with more than 1 BSN!\n",
    "assert old_shape[0] == new_shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add geboorteland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select bsn, geboorteland\n",
    "from bias_analyse_wpi_pre_pilot.brp_rapport\n",
    "\"\"\"\n",
    "\n",
    "geboorteland_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geboorteland_df = geboorteland_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = X_test_enriched.shape\n",
    "X_test_enriched = X_test_enriched.merge(geboorteland_df, how=\"left\", on=\"bsn\")\n",
    "new_shape = X_test_enriched.shape\n",
    "\n",
    "# Assert that the number of rows didn't change. If it did, we have BSNs with more than 1 geboorteland.\n",
    "assert old_shape[0] == new_shape[0]\n",
    "\n",
    "X_test_enriched[\"geboorteland\"] = pd.Categorical(X_test_enriched['geboorteland'])\n",
    "X_test_enriched[\"geboorteland_code\"] = X_test_enriched['geboorteland'].cat.codes\n",
    "\n",
    "geboorteland_mapping = dict(enumerate(X_test_enriched[\"geboorteland\"].cat.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add burgerlijke staat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H = huwelijk\n",
    "- P = geregistreerd partnerschap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"select bsn, soort_verbintenis, datum_sluiting, datum_ontbinding\n",
    "from bias_analyse_wpi_pre_pilot.brp_rapport\n",
    "\"\"\"\n",
    "\n",
    "burg_staat_df = pd.read_sql(sql_query, db_url_from_config(connection_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "burg_staat_df[\"datum_sluiting\"] = pd.to_datetime(burg_staat_df[\"datum_sluiting\"].replace(dt.date(1001, 1, 1), pd.Timestamp.min))\n",
    "burg_staat_df[\"datum_ontbinding\"] = pd.to_datetime(burg_staat_df[\"datum_ontbinding\"].replace(dt.date(1001, 1, 1), pd.Timestamp.min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_civil_status_at_date(civil_status_df, bsn, date):\n",
    "    df = civil_status_df[civil_status_df[\"bsn\"] == bsn]\n",
    "    df = df[df[\"datum_sluiting\"].isna() | (df[\"datum_sluiting\"] <= date)]\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        logger.warning(f\"BSN not found in dataframe, assuming that civil status is 'single': {bsn}\")\n",
    "        return \"single\"\n",
    "    \n",
    "    # `datum_sluiting` is always filled in our dump for marriage/partnership (H/P).\n",
    "    # So if all NaN, then there no partnership/marriage in the BRP.\n",
    "    if df[\"datum_sluiting\"].isna().mean() == 1:\n",
    "        civil_status = \"single\"\n",
    "        \n",
    "    else:            \n",
    "        # Check if last available partnership/marriage is still current.\n",
    "        df = df.sort_values(\"datum_sluiting\", ascending=False).drop_duplicates(subset=[\"bsn\"], keep=\"first\")\n",
    "        \n",
    "        if df[\"datum_ontbinding\"].isna().mean() == 1:\n",
    "            civil_status = \"partnership_or_married\"\n",
    "            \n",
    "        else:\n",
    "            civil_status = \"separated_or_divorced_or_widowed\"\n",
    "    \n",
    "    return civil_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_enriched[\"burgerlijke_staat\"] = [get_civil_status_at_date(burg_staat_df, row[\"bsn\"], row[\"dtaanvraag\"]) for i, row in X_test_enriched.iterrows()]\n",
    "\n",
    "X_test_enriched[\"burgerlijke_staat\"] = pd.Categorical(X_test_enriched['burgerlijke_staat'])\n",
    "X_test_enriched[\"burgerlijke_staat_code\"] = X_test_enriched['burgerlijke_staat'].cat.codes\n",
    "\n",
    "burgerlijke_staat_mapping = dict(enumerate(X_test_enriched[\"burgerlijke_staat\"].cat.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepilot_resultaten = pd.read_excel(\"2022.05.23_Merged_pre-pilot_templates.xlsx\", header=1, sheet_name=\"Template\")\n",
    "prepilot_removed_applications = pd.read_excel(\"2022.05.23_Merged_pre-pilot_templates.xlsx\", header=1, sheet_name=\"Removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the people that got removed during the prepilot due to being BD or other reasons.\n",
    "X_test = X_test[~X_test[\"subjectnr\"].isin(prepilot_removed_applications[\"Administratienummer\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with prepilot results to X_test.\n",
    "prepilot_resultaten[\"result_prepilot\"] = prepilot_resultaten[\"Label\"].replace({\"Onderzoekswaardig\": 1, \"Niet onderzoekswaardig\": 0})\n",
    "X_test = X_test.merge(prepilot_resultaten[[\"Dienstnummer\", \"result_prepilot\"]], how=\"left\", left_on=\"application_dienstnr\", right_on=\"Dienstnummer\")\n",
    "\n",
    "# Check that all prepilot results got merged to X_test.\n",
    "assert X_test[\"result_prepilot\"].value_counts().sum() == len(prepilot_resultaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"included_in_prepilot\"] = X_test[\"application_dienstnr\"].isin(prepilot_resultaten[\"Dienstnummer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"selected_by_model_not_process\"] = (X_test[\"model_prob\"] >= 0.63) & ~X_test[\"is_onderzoek_hh\"]\n",
    "X_test[\"selected_by_process_not_model\"] = (X_test[\"model_prob\"] < 0.63) & X_test[\"is_onderzoek_hh\"]\n",
    "X_test[\"selected_by_both\"] = (X_test[\"model_prob\"] >= 0.63) & X_test[\"is_onderzoek_hh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_to_compare = X_test[X_test[\"dtaanvraag\"] >= X_test.loc[X_test[\"included_in_prepilot\"], \"dtaanvraag\"].min()]\n",
    "# X_test_to_compare = X_test_to_compare[X_test_to_compare[[\"selected_by_model_not_process\", \"selected_by_process_not_model\", \"selected_by_both\"]].sum(axis=1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An application cannot fall in more than 1 category.\n",
    "assert X_test_to_compare[[\"selected_by_model_not_process\", \"selected_by_process_not_model\", \"selected_by_both\"]].sum(axis=1).max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Geselecteerd door model, niet door proces: model_prob >= 0.63 & heeft geen HH label\n",
    "    * Hiervoor hebben we een label als het in de prepilot is onderzocht.\n",
    "    * Ofwel model heeft het goed en proces fout, ofewel proces heeft het goed en model fout.\n",
    "- Geselecteerd door proces, niet door model: heeft een HH label & model_prob < 0.63\n",
    "    * Hiervoor hebben we een label uit het proces (= model label, oftewel kolom 'onderzoekswaardig').\n",
    "    * Ofwel model heeft het goed en proces fout, ofewel proces heeft het goed en model fout.\n",
    "- Geselecteerd door beide: heeft een HH label & model_prob >= 0.63\n",
    "    * Hiervoor hebben we een label uit het proces (= model label, oftewel kolom 'onderzoekswaardig').\n",
    "    * Model en proces hebben het of allebei goed, of allebei fout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_to_compare.shape)\n",
    "X_test_to_compare = X_test_to_compare[X_test_to_compare[\"bijzondere_doelgroep_address\"] != 1]\n",
    "print(X_test_to_compare.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_enriched = X_test_enriched.rename(columns={\n",
    "    \"nationaliteit1_persoon\": \"nationaliteit_code\",\n",
    "    \"postcodenum_adres\": \"postcodenum\",\n",
    "    \"geslacht_persoon\": \"geslacht\",\n",
    "})\n",
    "\n",
    "external_bias_columns = [\n",
    "    \"geslacht\",\n",
    "    \"leeftijd\",\n",
    "    \"nationaliteit_code\",\n",
    "    \"postcodenum\",\n",
    "    \"geboorteland_code\",\n",
    "    \"burgerlijke_staat_code\",\n",
    "]\n",
    "\n",
    "data_to_analyze = prep.transform(X_test_to_compare)\n",
    "data_to_analyze.index = X_test_to_compare[\"application_dienstnr\"]\n",
    "\n",
    "data_to_analyze[\"onderzoekswaardig\"] = X_test_to_compare[\"onderzoekswaardig\"].replace({True: 1, False: 0}).values\n",
    "data_to_analyze[\"included_in_prepilot\"] = X_test_to_compare[\"included_in_prepilot\"].values\n",
    "\n",
    "# For those applications where we have a result from the prepilot, replace the label with the result from the prepilot.\n",
    "dienstnr_with_result_from_prepilot = X_test_to_compare.loc[~X_test_to_compare[\"result_prepilot\"].isna(), \"application_dienstnr\"]\n",
    "data_to_analyze.loc[dienstnr_with_result_from_prepilot, \"onderzoekswaardig\"] = X_test_to_compare.set_index(\"application_dienstnr\").loc[dienstnr_with_result_from_prepilot, \"result_prepilot\"]\n",
    "\n",
    "data_to_analyze = data_to_analyze.merge(X_test_enriched.set_index(\"application_dienstnr\")[external_bias_columns], left_index=True, right_index=True, how=\"left\")\n",
    "data_to_analyze = data_to_analyze.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\n",
    "    (\"selected_by_model_not_process_and_in_prepilot\", \"afgewezen\"),  # Selected *only* by the model AND investigated in the prepilot AND afgewezen by ICer\n",
    "    (\"selected_by_model_not_process_and_in_prepilot\", \"niet_afgewezen\"),  # Selected *only* by the model AND investigated in the prepilot AND not afgewezen by ICer\n",
    "    (\"selected_by_model_not_process_overall\", \"afgewezen\"),  # Selected *only* by the model AND afgewezen by ICer, regardless whether investigated in prepilot or not\n",
    "    (\"selected_by_model_not_process_overall\", \"niet_afgewezen\"),  # Selected *only* by the model AND not afgewezen by ICer, regardless whether investigated in prepilot or not\n",
    "    (\"selected_by_process_not_model\", \"all\"),  # Selected *only* by the current process, i.e. HH onderzoek has already been done, but model scores it <0.63\n",
    "    (\"selected_by_both\", \"all\"),  # Selected by both the model and the current process\n",
    "    (\"all_data\", \"all\"),  # All data that was selected either by model or process or both or neither\n",
    "]\n",
    "\n",
    "original_sizes = {}\n",
    "\n",
    "datasets_to_analyze = {}\n",
    "\n",
    "for t in types:\n",
    "    if t[0] == \"all_data\":\n",
    "        # Select everything regardless of selection by model/process.\n",
    "        condition1 = np.repeat(True, len(X_test_to_compare))\n",
    "    else:\n",
    "        relevant_col = t[0].replace(\"_and_in_prepilot\", \"\").replace(\"_overall\", \"\")  # Strip parts of the string to get to column name that's relevant for the selection.\n",
    "        condition1 = X_test_to_compare[relevant_col]\n",
    "    \n",
    "    if t[1] == \"afgewezen\":\n",
    "        condition2 = X_test_to_compare[\"afgewezen\"]\n",
    "    elif t[1] == \"niet_afgewezen\":\n",
    "        condition2 = ~X_test_to_compare[\"afgewezen\"]\n",
    "    else:\n",
    "        # Select everything regardless of afgewezen/niet afgewezen.\n",
    "        condition2 = np.repeat(True, len(X_test_to_compare))\n",
    "    \n",
    "    idx_to_select = X_test_to_compare.loc[condition1 & condition2, \"application_dienstnr\"]\n",
    "    idx_to_select = set(idx_to_select).intersection(set(data_to_analyze.index))\n",
    "    \n",
    "    datasets_to_analyze[t] = data_to_analyze.loc[idx_to_select]\n",
    "    \n",
    "    original_sizes[t] = len(datasets_to_analyze[t])\n",
    "    \n",
    "    if \"_and_in_prepilot\" in t[0]:\n",
    "        datasets_to_analyze[t] = datasets_to_analyze[t].loc[datasets_to_analyze[t][\"included_in_prepilot\"]]\n",
    "        \n",
    "    datasets_to_analyze[t] = datasets_to_analyze[t].drop(\"included_in_prepilot\", axis=1)\n",
    "    \n",
    "    print(t)\n",
    "    print(f\"Definitive dataset size: {len(datasets_to_analyze[t])}\")\n",
    "    print(f\"Original dataset size: {original_sizes[t]}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_to_check = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 = unknown\n",
    "- 1 = male\n",
    "- 2 = female\n",
    "\n",
    "Note that we only compare male vs. female, because we don't have enough samples with unknown gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"geslacht\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_analyze = data_to_analyze[data_to_analyze[\"geslacht\"] != 0]\n",
    "features_to_check[\"geslacht\"] = [[1], [2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"leeftijd\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"leeftijd\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"leeftijd_split1\"] = [0, 100, 40, 1]\n",
    "features_to_check[\"leeftijd_split2\"] = [0, 100, 50, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"west-nonwest-nationalities.json\", 'r') as j:\n",
    "    west_nonwest_nationalities = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for code, nationality in zip(data_to_analyze[\"nationaliteit_code\"].value_counts().iteritems(), data_to_analyze[\"nationaliteit_code\"].map(nationaliteit_mapping).value_counts().iteritems()):\n",
    "    print(f\"Count: {nationality[1]:<5} Code: {int(code[0]):<5} {nationality[0]:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_mapping = {v: k for k,v in nationaliteit_mapping.items()}\n",
    "west_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_nationalities[\"west\"]]\n",
    "nonwest_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_nationalities[\"nonwest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze_no_unknown_nationality = data_to_analyze[(data_to_analyze[\"nationaliteit_code\"] != 0)]\n",
    "\n",
    "# Check that all nationality codes got assigned to west/nonwest except 0 = unknown.\n",
    "assert (data_to_analyze_no_unknown_nationality[\"nationaliteit_code\"].isin(west_codes) | data_to_analyze_no_unknown_nationality[\"nationaliteit_code\"].isin(nonwest_codes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"nationaliteit_code_split1\"] = [west_codes, nonwest_codes]  # West vs. non-west\n",
    "features_to_check[\"nationaliteit_code_split2\"] = [\n",
    "    [1], \n",
    "    [n for n in data_to_analyze[\"nationaliteit_code\"].unique() if n not in [0, 1]]  # Dutch vs. non-Dutch\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"west-nonwest-countries.json\", 'r') as j:\n",
    "    west_nonwest_countries = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for code, country in zip(data_to_analyze[\"geboorteland_code\"].value_counts().iteritems(), data_to_analyze[\"geboorteland_code\"].map(geboorteland_mapping).value_counts().iteritems()):\n",
    "    print(f\"Count: {country[1]:<5} Code: {int(code[0]):<5} {country[0]:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_mapping = {v: k for k,v in geboorteland_mapping.items()}\n",
    "west_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_countries[\"west\"]]\n",
    "nonwest_codes = [code for country, code in flipped_mapping.items() if country in west_nonwest_countries[\"nonwest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 = NaN, 127 = Onbekend\n",
    "data_to_analyze_no_unknown_nationality = data_to_analyze[~data_to_analyze[\"geboorteland_code\"].isin([-1, 127])]\n",
    "\n",
    "# Check that all country codes got assigned to west/nonwest.\n",
    "assert (data_to_analyze_no_unknown_nationality[\"geboorteland_code\"].isin(west_codes) | data_to_analyze_no_unknown_nationality[\"geboorteland_code\"].isin(nonwest_codes)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"geboorteland_code_split1\"] = [west_codes, nonwest_codes]  # West vs. non-west\n",
    "features_to_check[\"geboorteland_code_split2\"] = [\n",
    "    [114], \n",
    "    [n for n in data_to_analyze[\"geboorteland_code\"].unique() if n not in [114, -1, 127]]  # Dutch vs. non-Dutch\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Civil status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code, burg_staat in zip(data_to_analyze[\"burgerlijke_staat_code\"].value_counts().iteritems(), data_to_analyze[\"burgerlijke_staat_code\"].map(burgerlijke_staat_mapping).value_counts().iteritems()):\n",
    "    print(f\"Count: {burg_staat[1]:<5} Code: {int(code[0]):<5} {burg_staat[0]:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv = [1, 2]  # single of separated_or_divorced_or_widowed\n",
    "unpriv = [0]  # partnership_or_married\n",
    "features_to_check[\"burgerlijke_staat_code\"] = [priv, unpriv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: deelnames_started_percentage_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"deelnames_started_percentage_last_year\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"deelnames_started_percentage_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in types:\n",
    "    datasets_to_analyze[t][\"deelnames_started_percentage_last_year_equals_zero\"] = (datasets_to_analyze[t][\"deelnames_started_percentage_last_year\"] == 0)*1\n",
    "    datasets_to_analyze[t][\"deelnames_started_percentage_last_year_equals_one\"] = (datasets_to_analyze[t][\"deelnames_started_percentage_last_year\"] == 1)*1\n",
    "\n",
    "# This means: People who started nothing last year (incl. those who weren't in the system last year) vs. people who started something or everything.\n",
    "features_to_check[\"deelnames_started_percentage_last_year_equals_zero\"] = [\n",
    "    [0], [1]\n",
    "]\n",
    "# This means: People who started everything last year vs. those who didn't start everything or who weren't in the system last year.\n",
    "features_to_check[\"deelnames_started_percentage_last_year_equals_one\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: at_least_one_address_in_amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"at_least_one_address_in_amsterdam\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"at_least_one_address_in_amsterdam\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: active_address_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"active_address_count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"active_address_count\"] = [\n",
    "    [1], [2, 3]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: days_since_last_relocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"days_since_last_relocation\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"days_since_last_relocation\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_value = 365\n",
    "features_to_check[\"days_since_last_relocation\"] = [\n",
    "    [n for n in data_to_analyze[\"days_since_last_relocation\"].unique() if n > split_value],  # Same address for a long time\n",
    "    [n for n in data_to_analyze[\"days_since_last_relocation\"].unique() if n <= split_value]  # Moved in the past year\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: days_since_last_dienst_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"days_since_last_dienst_end\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"days_since_last_dienst_end_split1\"] = [\n",
    "    [99999],  # No dienst last year\n",
    "    [n for n in data_to_analyze[\"days_since_last_dienst_end\"].unique() if n != 99999]  # Had a dienst last year\n",
    "]\n",
    "\n",
    "split_value = 60\n",
    "features_to_check[\"days_since_last_dienst_end_split2\"] = [\n",
    "    [n for n in data_to_analyze[\"days_since_last_dienst_end\"].unique() if n > split_value],  # Dienst longer than 60 days ago\n",
    "    [n for n in data_to_analyze[\"days_since_last_dienst_end\"].unique() if n <= split_value]  # Dienst within last 60 days\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: has_medebewoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"has_medebewoner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"has_medebewoner\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: avg_percentage_maatregel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"avg_percentage_maatregel\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we have too few samples to say anything meaningful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: total_vermogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"total_vermogen\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"total_vermogen\"].hist(bins=300, figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_value = 0\n",
    "features_to_check[\"total_vermogen_split1\"] = [ \n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n >= split_value],  # Greater than or equal to zero wealth\n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n < split_value]    # Negative wealth\n",
    "]\n",
    "\n",
    "split_value = 0\n",
    "features_to_check[\"total_vermogen_split2\"] = [ \n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n > split_value],  # Positive wealth\n",
    "    [n for n in data_to_analyze[\"total_vermogen\"].unique() if n < split_value]    # Negative wealth\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: afspraken_no_show_count_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"afspraken_no_show_count_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"afspraken_no_show_count_last_year\"] = [\n",
    "    [0], [1, 2, 3]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: has_partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"has_partner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"has_partner\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: sum_inkomen_bruto_was_mean_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"sum_inkomen_bruto_was_mean_imputed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"sum_inkomen_bruto_was_mean_imputed\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: applied_for_same_product_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"applied_for_same_product_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"applied_for_same_product_last_year\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: received_same_product_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"received_same_product_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"received_same_product_last_year\"] = [\n",
    "    [0], [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: afspraken_no_contact_count_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"afspraken_no_contact_count_last_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"afspraken_no_contact_count_last_year\"] = [\n",
    "    [0], [1, 2, 3, 4, 5]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature: sum_inkomen_bruto_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_analyze[\"sum_inkomen_bruto_value\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check[\"sum_inkomen_bruto_value\"] = [ \n",
    "    [0],  # No income\n",
    "    [n for n in data_to_analyze[\"sum_inkomen_bruto_value\"].unique() if n > 0]    # Has non-zero income\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import defaultdict\n",
    "from itertools import compress\n",
    "from string import digits\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from numpy.core.records import ndarray\n",
    "\n",
    "from bias_collection.helpers import create_AIF360_groups\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class BiasAnalyzer:\n",
    "\n",
    "    log_info_by_metric = {\n",
    "        \"balanced_accuracy\": \"\",\n",
    "        \"accuracy_privileged\": \"\",\n",
    "        \"accuracy_unprivileged\": \"\",\n",
    "        \"average_odds_difference\": (\n",
    "            \"Average odds difference is computed as average difference of false positive rate \"\n",
    "            \"(false positives / negatives) and true positive rate (true positives / positives) \"\n",
    "            \"between unprivileged and privileged groups. The ideal value of this metric is 0. A \"\n",
    "            \"value of < 0 implies higher benefit for the privileged group and a value > 0 \"\n",
    "            \"implies higher benefit for the unprivileged group. Fairness for this metric is \"\n",
    "            \"between -0.1 and 0.1.\"\n",
    "        ),\n",
    "        \"disparate_impact\": (\n",
    "            \"Disparate impact is computed as the ratio of rate of favorable outcome for the unprivileged group to \"\n",
    "            \"that of the privileged group. The ideal value of this metric is 1.0. A value < 1 implies higher benefit \"\n",
    "            \"for the privileged group and a value > 1 implies a higher benefit for the unprivileged group. Fairness \"\n",
    "            \"for this metric is between 0.8 and 1.25.\"\n",
    "        ),\n",
    "        \"statistical_parity_difference\": (\n",
    "            \"Statistical parity difference is computed as the difference of the rate of favorable outcomes received \"\n",
    "            \"by the unprivileged group to the privileged group. The ideal value of this metric is 0. Fairness for \"\n",
    "            \"this metric is between -0.1 and 0.1.\"\n",
    "        ),\n",
    "        \"false_discovery_rate_difference\": (\n",
    "            \"The false discovery rate difference expresses the difference in percentage points between the groups in \"\n",
    "            \"how likely it is that a selected (by the model) group member should not have been selected in reality. \"\n",
    "            \"The ideal value of this metric is 0. A value < 0 implies a higher FDR for the privileged group and a \"\n",
    "            \"value > 0 implies a higher FDR for the unprivileged group.\"\n",
    "        ),\n",
    "        \"false_discovery_rate_ratio\": (\n",
    "            \"The false discovery rate ratio expresses the ratio between the groups of how likely it is that a \"\n",
    "            \"selected (by the model) group member should not have been selected in reality. The ideal value of this \"\n",
    "            \"metric is 1. A value < 1 implies a higher FDR for the privileged group and a value > 0 implies a higher \"\n",
    "            \"FDR for the unprivileged group.\"\n",
    "        ),\n",
    "        \"false_positive_rate_difference\": (\n",
    "            \"The false positive rate difference expresses the difference in percentage points between the groups in \"\n",
    "            \"how likely it is that a group member who should not have been selected in reality is (wrongly) selected \"\n",
    "            \"by the model. The ideal value of this metric is 0. A value < 0 implies a higher FPR for the privileged \"\n",
    "            \"group and a value > 0 implies a higher FPR for the unprivileged group.\"\n",
    "        ),\n",
    "        \"false_positive_rate_ratio\": (\n",
    "            \"The false positive rate ratio expresses the ratio between the groups of how likely it is that a group \"\n",
    "            \"member who should not have been selected in reality is (wrongly) selected by the model. The ideal value \"\n",
    "            \"of this metric is 1. A value < 1 implies a higher FPR for the privileged group and a value > 0 implies \"\n",
    "            \"a higher FPR for the unprivileged group.\"\n",
    "        ),\n",
    "        \"generalized_entropy_index\": \"\",\n",
    "        \"false_positive_group_size_difference\": (\n",
    "            \"The false positive group size difference expresses the difference in percentage points between the \"\n",
    "            \"groups of a random group member's chance to be wrongly selected by the model. The ideal value of this \"\n",
    "            \"metric is 0. A value < 0 implies a higher FP-GZ for the privileged group and a value > 0 implies a \"\n",
    "            \"higher FP-GZ for the unprivileged group.\"\n",
    "        ),\n",
    "        \"false_positive_group_size_ratio\": (\n",
    "            \"The false positive group size ratio expresses the ratio between the groups of a random group member's \"\n",
    "            \"chance to be wrongly selected by the model. The ideal value of this metric is 1. A value < 1 implies a \"\n",
    "            \"higher FP-GZ for the privileged group and a value > 1 implies a higher FP-GZ for the unprivileged group.\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    def __init__(self, metrics: List[str] = None):\n",
    "        \"\"\"Class to analyze bias in a model's predictions. It uses AIF360 framework.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metrics\n",
    "            List with the names of the metrics that should be calculated. These\n",
    "            metrics should exist as methods without an argument in the AIF360\n",
    "            `ClassificationMetric` class, or as methods of this class itself if\n",
    "            they are not in AIF360 or the AIF360 method requires an argument.\n",
    "            Defaults to None, in which case all available metrics are calculated.\n",
    "        \"\"\"\n",
    "        if metrics:\n",
    "            self._validate_metrics_list(metrics)\n",
    "            self.metrics = metrics\n",
    "            # Balanced accuracy is always calculated to pick a best classification\n",
    "            # threshold.\n",
    "            if \"balanced_accuracy\" not in metrics:\n",
    "                metrics.append(\"balanced_accuracy\")\n",
    "        else:\n",
    "            self.metrics = list(self.log_info_by_metric.keys())\n",
    "\n",
    "    def _validate_metrics_list(self, metrics):\n",
    "        \"\"\"Validate that all specified metrics have an implementation in either\n",
    "        `ClassificationMetric` from AIF360 or as a method of this class.\n",
    "        \"\"\"\n",
    "        metrics_not_implemented = [\n",
    "            not (hasattr(ClassificationMetric, m) | hasattr(self, m)) for m in metrics\n",
    "        ]\n",
    "        if any(metrics_not_implemented):\n",
    "            raise ValueError(\n",
    "                f\"The following metrics were specified, but are not implemented: \"\n",
    "                f\"{list(compress(metrics, metrics_not_implemented))}\"\n",
    "            )\n",
    "\n",
    "    def analyze_features(\n",
    "        self,\n",
    "        data_to_analyze: pd.DataFrame,\n",
    "        model,\n",
    "        sensitive_features: Dict,\n",
    "        outpath: str,\n",
    "        label_column_name: str,\n",
    "        thresholds: list = [0.5],\n",
    "        external_variables: list = None,\n",
    "        print_metric_explanations: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Runs a bias analysis over the specified features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_to_analyze\n",
    "            Data to be analysed,\n",
    "            including external variables that are not used during the scoring but they need to be measured.\n",
    "        model\n",
    "            Model that performs the classification\n",
    "        sensitive_features\n",
    "            Dictionary containing the features to be analyzed.\n",
    "            The keys of the dictionary are the features and the value could be of three types:\n",
    "            - a list containing:\n",
    "                [lower_value, higher_value, split_value, step]\n",
    "                The first group is from lower value to (but not including) the split value, the second from the split\n",
    "                value to (but not including) the higher value.\n",
    "                Example:\n",
    "                {'feature': [0,4,2,1]}\n",
    "                First group: [0,1]\n",
    "                Second group: [2,3]\n",
    "\n",
    "            - a list containing two lists with the privileged and unprivileged values:\n",
    "                [[privileged values], [unprivileged values]]\n",
    "\n",
    "            - a dictionary containing:\n",
    "                privileged_groups: List[Dict]\n",
    "                    List of dictionaries, each dictionary contains the name of the feature\n",
    "                    and the value that is considered privileged.\n",
    "                    [{'aantal_kamers': 0}, {'aantal_kamers': 1}, {'aantal_kamers': 2}, {'aantal_kamers': 3}]\n",
    "                unprivileged_groups: List[Dict]\n",
    "                    List of dictionaries, each dictionary contains the name of the feature\n",
    "                    and the value that is considered unprivileged.\n",
    "        outpath\n",
    "            Path where to store the results of the analysis.\n",
    "        label_column_name\n",
    "            Name of the column containing the label (Needs to be present in data_to_analyze)\n",
    "        thresholds\n",
    "            List of different thresholds to define positive and negative predicted values from the score.\n",
    "        external_variables\n",
    "            List of features that are not used by the model but we want to analyze\n",
    "        print_metric_explanations\n",
    "            Whether or not to print explanations of the calculated metrics\n",
    "        \"\"\"\n",
    "        # If `feature` ends with \"_splitX\" with X being some number, then multiple splits have been\n",
    "        # specified for this feature and we have to get the actual feature name.\n",
    "        # TODO: This is kind of hacky, it'd be nicer to have, for example, a dictionary with the\n",
    "        #  feature name as the key and as value a dict or list with the multiple splits. This requires some\n",
    "        #  restructuring of the code to detect if a feature has only one split specified, or multiple, and then to\n",
    "        #  output the results in a good way.\n",
    "        protected_attribute_names = [\n",
    "            feature.rstrip(digits).replace(\"_split\", \"\")\n",
    "            for feature in sensitive_features.keys()\n",
    "        ]\n",
    "\n",
    "        binary_label_dataset_to_analyse = BinaryLabelDataset(\n",
    "            df=data_to_analyze,\n",
    "            label_names=[label_column_name],\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "        )\n",
    "\n",
    "        if external_variables:\n",
    "            binary_label_dataset_to_score = BinaryLabelDataset(\n",
    "                df=data_to_analyze.drop(columns=external_variables),\n",
    "                label_names=[label_column_name],\n",
    "                protected_attribute_names=[\n",
    "                    x for x in protected_attribute_names if x not in external_variables\n",
    "                ],\n",
    "            )\n",
    "        else:\n",
    "            binary_label_dataset_to_score = binary_label_dataset_to_analyse\n",
    "\n",
    "        val_metrics, all_group_splits = self.calculate_metrics(\n",
    "            input_dataframe=data_to_analyze,\n",
    "            dataset=binary_label_dataset_to_analyse,\n",
    "            dataset_to_score=binary_label_dataset_to_score,\n",
    "            model=model,\n",
    "            thresh_arr=thresholds,\n",
    "            sensitive_features=sensitive_features,\n",
    "            label_column_name=label_column_name,\n",
    "        )\n",
    "\n",
    "        self.log_metrics(\n",
    "            val_metrics, thresholds, all_group_splits, print_metric_explanations\n",
    "        )\n",
    "        self.metrics_to_csv(val_metrics, all_group_splits, outpath)\n",
    "\n",
    "        return val_metrics\n",
    "\n",
    "    def calculate_metrics(\n",
    "        self,\n",
    "        input_dataframe: pd.DataFrame,\n",
    "        dataset: BinaryLabelDataset,\n",
    "        dataset_to_score: BinaryLabelDataset,\n",
    "        model,\n",
    "        thresh_arr: ndarray,\n",
    "        sensitive_features: Dict,\n",
    "        label_column_name: str,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calculate bias metrics to understand if the features are biased or not.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dataframe\n",
    "            Contains the data to be checked in DataFrame format\n",
    "        dataset\n",
    "            Contains the data to be checked\n",
    "        dataset_to_score\n",
    "            Contains the data to be used for scoring\n",
    "        model\n",
    "            Model used for the classification\n",
    "        thresh_arr\n",
    "            Array of possibles thresholds of the classification\n",
    "        sensitive_features\n",
    "            Dictionary containing the biased features to analyse\n",
    "        label_column_name\n",
    "            Name of the column containing the label (Needs to be present in data_to_analyze)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        metric_arrs:\n",
    "            Dictionary containing all the metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # sklearn classifier\n",
    "            y_val_pred_prob = model.predict_proba(dataset_to_score.features)\n",
    "            pos_ind = np.where(model.classes_ == dataset_to_score.favorable_label)[0][0]\n",
    "        except AttributeError:\n",
    "            # aif360 inprocessing algorithm\n",
    "            y_val_pred_prob = model.predict(dataset_to_score).scores\n",
    "            pos_ind = 0\n",
    "\n",
    "        metric_arrs = defaultdict(dict)  # type: Dict[str, Dict[str, Any]]\n",
    "        all_group_splits = defaultdict(dict)  # type: Dict[str, Dict[str, Any]]\n",
    "        protected_attribute_names = list(sensitive_features.keys())\n",
    "        for thresh in thresh_arr:\n",
    "            for feature in protected_attribute_names:\n",
    "                # If `feature` ends with \"_splitX\" with X being some number, then multiple splits have been\n",
    "                # specified for this feature and we have to get the actual feature name.\n",
    "                actual_feature_name = feature.rstrip(digits).replace(\"_split\", \"\")\n",
    "                if isinstance(sensitive_features[feature], list):\n",
    "                    (privileged_groups, unprivileged_groups,) = create_AIF360_groups(\n",
    "                        actual_feature_name, sensitive_features[feature]\n",
    "                    )\n",
    "                elif isinstance(sensitive_features[feature], dict):\n",
    "                    privileged_groups = sensitive_features[feature][\"privileged_groups\"]\n",
    "                    unprivileged_groups = sensitive_features[feature][\n",
    "                        \"unprivileged_groups\"\n",
    "                    ]\n",
    "                else:\n",
    "                    raise Exception(\n",
    "                        f\"\"\"Wrong sensitive_features type, it must be list or dict, received:\n",
    "                            {type(sensitive_features[feature])}\"\"\"\n",
    "                    )\n",
    "\n",
    "                dataset_pred = dataset.copy()\n",
    "                y_val_pred = (y_val_pred_prob[:, pos_ind] > thresh).astype(np.float64)\n",
    "                dataset_pred.labels = y_val_pred\n",
    "                input_dataframe = input_dataframe.assign(y_val_pred=y_val_pred)\n",
    "\n",
    "                all_group_splits[feature][\n",
    "                    \"privileged_values\"\n",
    "                ] = self.unpack_group_dictionary(privileged_groups, actual_feature_name)\n",
    "                all_group_splits[feature][\n",
    "                    \"unprivileged_values\"\n",
    "                ] = self.unpack_group_dictionary(\n",
    "                    unprivileged_groups, actual_feature_name\n",
    "                )\n",
    "                all_group_splits[feature][\"n_privileged\"] = (\n",
    "                    input_dataframe[actual_feature_name]\n",
    "                    .isin(all_group_splits[feature][\"privileged_values\"])\n",
    "                    .sum()\n",
    "                )\n",
    "                all_group_splits[feature][\"n_unprivileged\"] = (\n",
    "                    input_dataframe[actual_feature_name]\n",
    "                    .isin(all_group_splits[feature][\"unprivileged_values\"])\n",
    "                    .sum()\n",
    "                )\n",
    "\n",
    "                metric = ClassificationMetric(\n",
    "                    dataset,\n",
    "                    dataset_pred,\n",
    "                    privileged_groups=privileged_groups,\n",
    "                    unprivileged_groups=unprivileged_groups,\n",
    "                )\n",
    "\n",
    "                metric_arrs[feature] = defaultdict(list)\n",
    "\n",
    "                for m in self.metrics:\n",
    "                    try:\n",
    "                        m_func = getattr(metric, m)\n",
    "                        metric_arrs[feature][m].append(m_func())\n",
    "                    except AttributeError:\n",
    "                        m_func = getattr(self, m)\n",
    "                        metric_arrs[feature][m].append(\n",
    "                            m_func(\n",
    "                                feature=actual_feature_name,\n",
    "                                input_dataframe=input_dataframe,\n",
    "                                privileged_groups=privileged_groups,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                label_column_name=label_column_name,\n",
    "                                classification_metric=metric,\n",
    "                            )\n",
    "                        )\n",
    "                        \n",
    "#             for pred, true in zip(y_val_pred, dataset.labels):\n",
    "#                 logger.info(f\"{pred} - {true}\")\n",
    "            logger.warning(f\"Nr prediction positive: {(y_val_pred == 1).sum()}\")\n",
    "            logger.warning(f\"Nr prediction negative: {(y_val_pred == 0).sum()}\")\n",
    "        return metric_arrs, all_group_splits\n",
    "\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        metrics: Dict,\n",
    "        thresh_arr: ndarray,\n",
    "        all_group_splits: Dict,\n",
    "        print_metric_explanations: bool = False,\n",
    "    ):\n",
    "        \"\"\"Log the metrics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metrics\n",
    "            Dictionary containing the metrics\n",
    "        thresh_arr\n",
    "            Array of possible thresholds of the classification\n",
    "        all_group_splits\n",
    "            Dictionary containing the AIF360 group splits for all features\n",
    "        print_metric_explanations\n",
    "            Whether or not to print explanations of the calculated metrics\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        :\n",
    "        \"\"\"\n",
    "        for feature, metric_values in metrics.items():\n",
    "            logger.info(\n",
    "                f\"\\n\\n--------------- Bias Analysis {feature} ---------------\\n\"\n",
    "            )\n",
    "\n",
    "            logger.info(\n",
    "                f\"Privileged (n={all_group_splits[feature]['n_privileged']}): {all_group_splits[feature]['privileged_values']}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Unprivileged (n={all_group_splits[feature]['n_unprivileged']}): {all_group_splits[feature]['unprivileged_values']}\"\n",
    "            )\n",
    "\n",
    "            best_ind = np.argmax(metric_values[\"balanced_accuracy\"])\n",
    "            logger.info(\n",
    "                f\"Threshold corresponding to best balanced accuracy: {thresh_arr[best_ind]:.3f}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Best balanced accuracy: {metric_values['balanced_accuracy'][best_ind]:.3f}\"\n",
    "            )\n",
    "            logger.info(\"\\n\")\n",
    "\n",
    "            for m_name, m_values in metric_values.items():\n",
    "                if m_name == \"balanced_accuracy\":\n",
    "                    continue\n",
    "                logger.info(f\"{m_name + ':': <40} {m_values[best_ind]:.3f}\")\n",
    "                if print_metric_explanations:\n",
    "                    logger.info(f\"{self.log_info_by_metric[m_name]}\\n\")\n",
    "\n",
    "            logger.info(\"\\n---------------------------------------------\")\n",
    "\n",
    "    def metrics_to_csv(self, metrics: Dict, group_splits: Dict, csv_path: str):\n",
    "        data = []\n",
    "        for feature, value in metrics.items():\n",
    "            best_ind = np.argmax(value[\"balanced_accuracy\"])\n",
    "            data.append(feature)\n",
    "            for metric in self.metrics:\n",
    "                data.append(value[metric][best_ind])\n",
    "        column_names = [\"feature\"]\n",
    "        for metric in self.metrics:\n",
    "            column_names.append(metric)\n",
    "\n",
    "        metrics_df = pd.DataFrame(\n",
    "            np.array(data).reshape(-1, len(column_names)), columns=column_names\n",
    "        )\n",
    "\n",
    "        group_splits_df = pd.DataFrame.from_dict(group_splits).T\n",
    "\n",
    "        df = metrics_df.merge(group_splits_df, left_on=\"feature\", right_index=True)\n",
    "\n",
    "        outpath = f\"{csv_path}/bias_results.csv\"\n",
    "        logger.info(f\"Writing bias analysis results to {outpath}\")\n",
    "        df.to_csv(outpath, index=False)\n",
    "\n",
    "    def false_positive_group_size_difference(\n",
    "        self,\n",
    "        feature,\n",
    "        input_dataframe,\n",
    "        privileged_groups,\n",
    "        unprivileged_groups,\n",
    "        label_column_name,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        privileged_fp_group_size = self.calculate_fp_group_size(\n",
    "            input_dataframe, privileged_groups, feature, label_column_name\n",
    "        )\n",
    "        unprivileged_fp_group_size = self.calculate_fp_group_size(\n",
    "            input_dataframe, unprivileged_groups, feature, label_column_name\n",
    "        )\n",
    "        return unprivileged_fp_group_size - privileged_fp_group_size\n",
    "\n",
    "    def false_positive_group_size_ratio(\n",
    "        self,\n",
    "        feature,\n",
    "        input_dataframe,\n",
    "        privileged_groups,\n",
    "        unprivileged_groups,\n",
    "        label_column_name,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        privileged_fp_group_size = self.calculate_fp_group_size(\n",
    "            input_dataframe, privileged_groups, feature, label_column_name\n",
    "        )\n",
    "        unprivileged_fp_group_size = self.calculate_fp_group_size(\n",
    "            input_dataframe, unprivileged_groups, feature, label_column_name\n",
    "        )\n",
    "        return unprivileged_fp_group_size / privileged_fp_group_size\n",
    "\n",
    "    def calculate_fp_group_size(\n",
    "        self, data, group_to_use, feature_to_use, label_column_name\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The false positive / group size has been discovered into the Aequitas bias audit toolkit.\n",
    "        http://www.datasciencepublicpolicy.org/our-work/tools-guides/aequitas/\n",
    "\n",
    "        The metric replies the following question: \"What are your chances of being wrongly denied bailjust given your race?\"\n",
    "\n",
    "        data\n",
    "            Contains the data to be checked\n",
    "        group_to_use\n",
    "            Contains the privileged/unprivileged dictionary determining how the groups should be splitted.\n",
    "        feature_to_use\n",
    "            Contains the column name of the feature we are analyzing.\n",
    "        label_column_name\n",
    "            Name of the column containing the label (Needs to be present in data_to_analyze)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fp_group_size:\n",
    "            false positive / group size result.\n",
    "        \"\"\"\n",
    "        group_values = self.unpack_group_dictionary(group_to_use, feature_to_use)\n",
    "        group_filtered_df = data[data[feature_to_use].isin(group_values)]\n",
    "        fp_group_size = (\n",
    "            (group_filtered_df[\"y_val_pred\"] == 1)\n",
    "            & (group_filtered_df[label_column_name] == 0)\n",
    "        ).mean()\n",
    "        return fp_group_size\n",
    "\n",
    "    @staticmethod\n",
    "    def balanced_accuracy(classification_metric: ClassificationMetric, *args, **kwargs):\n",
    "        return (\n",
    "            classification_metric.true_positive_rate()\n",
    "            + classification_metric.true_negative_rate()\n",
    "        ) / 2\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy_privileged(\n",
    "        classification_metric: ClassificationMetric, *args, **kwargs\n",
    "    ):\n",
    "        return classification_metric.accuracy(False)\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy_unprivileged(\n",
    "        classification_metric: ClassificationMetric, *args, **kwargs\n",
    "    ):\n",
    "        return classification_metric.accuracy(False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def num_false_positives_privileged(\n",
    "        classification_metric: ClassificationMetric, *args, **kwargs\n",
    "    ):\n",
    "        return classification_metric.num_false_positives(True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def num_false_positives_unprivileged(\n",
    "        classification_metric: ClassificationMetric, *args, **kwargs\n",
    "    ):\n",
    "        return classification_metric.num_false_positives(False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def num_negatives_privileged(\n",
    "        classification_metric: ClassificationMetric, *args, **kwargs\n",
    "    ):\n",
    "        return classification_metric.num_negatives(True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def num_negatives_unprivileged(\n",
    "        classification_metric: ClassificationMetric, *args, **kwargs\n",
    "    ):\n",
    "        return classification_metric.num_negatives(False)\n",
    "\n",
    "    @staticmethod\n",
    "    def generalized_entropy_index(\n",
    "        classification_metric: ClassificationMetric, *args, **kwargs\n",
    "    ):\n",
    "        return classification_metric.generalized_entropy_index(alpha=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def unpack_group_dictionary(data: Dict, feature_to_unpack: str):\n",
    "        result = []\n",
    "        for group in data:\n",
    "            result.append(group[feature_to_unpack])\n",
    "        return sorted(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlwaysPositivePredictor():\n",
    "    \"\"\"Since we've already split the datasets going into the `data_to_analyze` parameter of the BiasAnalyzer by whether\n",
    "    or not something was selected by model and/or process, we don't have to make predictions anymore inside the BiasAnalyzer.\n",
    "    In those cases, this class can be used instead of the model for the `model` parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classes_ = np.array([0, 1])\n",
    "    \n",
    "    def predict_proba(self, X, y=None):\n",
    "        return np.vstack([np.repeat(0, len(X)), np.repeat(1, len(X))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "external_variables = external_bias_columns + [\n",
    "    \"deelnames_started_percentage_last_year_equals_zero\", \n",
    "    \"deelnames_started_percentage_last_year_equals_one\"\n",
    "]\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    \"num_false_positives_privileged\",\n",
    "    \"num_false_positives_unprivileged\",\n",
    "    \"num_negatives_privileged\",\n",
    "    \"num_negatives_unprivileged\",\n",
    "    \"false_positive_rate_difference\",\n",
    "    \"false_positive_rate_ratio\",\n",
    "    \"false_positive_group_size_difference\",\n",
    "    \"false_positive_group_size_ratio\",\n",
    "]\n",
    "\n",
    "for t in types:\n",
    "    logger.warning(t)\n",
    "    \n",
    "    outpath = f\"20220523_bias_report_bugs_solved/{t[0]}/{t[1]}\"\n",
    "    Path(outpath).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if (t[0] == \"selected_by_process_not_model\") | (t[0] == \"selected_by_both\"):\n",
    "        model_for_bias_analyzer = AlwaysPositivePredictor()\n",
    "    else:\n",
    "        model_for_bias_analyzer = clf\n",
    "\n",
    "    BiasAnalyzer(\n",
    "        metrics\n",
    "    ).analyze_features(\n",
    "        data_to_analyze=datasets_to_analyze[t],\n",
    "        model=model_for_bias_analyzer,\n",
    "        sensitive_features=features_to_check,\n",
    "        outpath=outpath,\n",
    "        thresholds=[0.63-0.000000000001],\n",
    "        label_column_name=label,\n",
    "        external_variables=external_variables,\n",
    "    #     print_metric_explanations=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_dfs = {}\n",
    "for t in types:\n",
    "    outpath = f\"20220523_bias_report_bugs_solved/{t[0]}/{t[1]}\"\n",
    "    inpath = outpath + \"/bias_results.csv\"\n",
    "    bias_dfs[t] = pd.read_csv(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_calculations = bias_dfs[('all_data', 'all')][[\"feature\", \"n_privileged\", \"n_unprivileged\", \"privileged_values\", \"unprivileged_values\"]]\n",
    "\n",
    "# Calculate multiplier to bring the afgewezen/niet-afgewezen samples from the prepilot to the same proportion as it is in the overall dataset.\n",
    "multiplier_afgewezen = (\n",
    "    bias_dfs[('selected_by_model_not_process_overall', 'afgewezen')][[\"n_privileged\", \"n_unprivileged\"]].values /\n",
    "    bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'afgewezen')][[\"n_privileged\", \"n_unprivileged\"]].values\n",
    ")\n",
    "multiplier_niet_afgewezen = (\n",
    "    bias_dfs[('selected_by_model_not_process_overall', 'niet_afgewezen')][[\"n_privileged\", \"n_unprivileged\"]].values /\n",
    "    bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'niet_afgewezen')][[\"n_privileged\", \"n_unprivileged\"]].values\n",
    ")\n",
    "\n",
    "# Scale number of false positives in prepilot investigations to the same proportions as in the overall dataset.\n",
    "scaled_num_false_positives_afgewezen = pd.DataFrame(\n",
    "    (\n",
    "        multiplier_afgewezen *\n",
    "        bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'afgewezen')][[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"]].values\n",
    "    ), \n",
    "    columns=[\n",
    "        \"scaled_num_false_positives_afgewezen_selected_by_model_privileged\", \n",
    "        \"scaled_num_false_positives_afgewezen_selected_by_model_unprivileged\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "scaled_num_false_positives_niet_afgewezen = pd.DataFrame(\n",
    "    (\n",
    "        multiplier_niet_afgewezen *\n",
    "        bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'niet_afgewezen')][[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"]].values\n",
    "    ), \n",
    "    columns=[\n",
    "        \"scaled_num_false_positives_niet_afgewezen_selected_by_model_privileged\", \n",
    "        \"scaled_num_false_positives_niet_afgewezen_selected_by_model_unprivileged\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "bias_calculations = pd.concat([\n",
    "    bias_calculations, \n",
    "    scaled_num_false_positives_afgewezen,\n",
    "    scaled_num_false_positives_niet_afgewezen,\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "bias_calculations[\"num_false_positives_model_privileged\"] = (\n",
    "    scaled_num_false_positives_afgewezen[\"scaled_num_false_positives_afgewezen_selected_by_model_privileged\"] +\n",
    "    scaled_num_false_positives_niet_afgewezen[\"scaled_num_false_positives_niet_afgewezen_selected_by_model_privileged\"] +\n",
    "    bias_dfs[('selected_by_both', 'all')][\"num_false_positives_privileged\"]\n",
    ")\n",
    "\n",
    "bias_calculations[\"num_false_positives_model_unprivileged\"] = (\n",
    "    scaled_num_false_positives_afgewezen[\"scaled_num_false_positives_afgewezen_selected_by_model_unprivileged\"] +\n",
    "    scaled_num_false_positives_niet_afgewezen[\"scaled_num_false_positives_niet_afgewezen_selected_by_model_unprivileged\"] +\n",
    "    bias_dfs[('selected_by_both', 'all')][\"num_false_positives_unprivileged\"]\n",
    ")\n",
    "\n",
    "bias_calculations[\"num_false_positives_process_privileged\"] = (\n",
    "    bias_dfs[('selected_by_process_not_model', 'all')][\"num_false_positives_privileged\"] +\n",
    "    bias_dfs[('selected_by_both', 'all')][\"num_false_positives_privileged\"]\n",
    ")\n",
    "\n",
    "bias_calculations[\"num_false_positives_process_unprivileged\"] = (\n",
    "    bias_dfs[('selected_by_process_not_model', 'all')][\"num_false_positives_unprivileged\"] +\n",
    "    bias_dfs[('selected_by_both', 'all')][\"num_false_positives_unprivileged\"]\n",
    ")\n",
    "\n",
    "bias_calculations[\"fp_group_size_process_privileged\"] = bias_calculations[\"num_false_positives_process_privileged\"] / bias_calculations[\"n_privileged\"]\n",
    "bias_calculations[\"fp_group_size_process_unprivileged\"] = bias_calculations[\"num_false_positives_process_unprivileged\"] / bias_calculations[\"n_unprivileged\"]\n",
    "\n",
    "bias_calculations[\"fp_group_size_process_diff\"] = bias_calculations[\"fp_group_size_process_unprivileged\"] - bias_calculations[\"fp_group_size_process_privileged\"]\n",
    "bias_calculations[\"fp_group_size_process_ratio\"] = bias_calculations[\"fp_group_size_process_unprivileged\"] / bias_calculations[\"fp_group_size_process_privileged\"]\n",
    "\n",
    "bias_calculations[\"fp_group_size_model_privileged\"] = bias_calculations[\"num_false_positives_model_privileged\"] / bias_calculations[\"n_privileged\"]\n",
    "bias_calculations[\"fp_group_size_model_unprivileged\"] = bias_calculations[\"num_false_positives_model_unprivileged\"] / bias_calculations[\"n_unprivileged\"]\n",
    "\n",
    "bias_calculations[\"fp_group_size_model_diff\"] = bias_calculations[\"fp_group_size_model_unprivileged\"] - bias_calculations[\"fp_group_size_model_privileged\"]\n",
    "bias_calculations[\"fp_group_size_model_ratio\"] = bias_calculations[\"fp_group_size_model_unprivileged\"] / bias_calculations[\"fp_group_size_model_privileged\"]\n",
    "\n",
    "\n",
    "n_model = pd.DataFrame(\n",
    "    (\n",
    "        bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'afgewezen')][[\"n_privileged\", \"n_unprivileged\"]].values + \n",
    "        bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'niet_afgewezen')][[\"n_privileged\", \"n_unprivileged\"]].values +\n",
    "        bias_dfs[('selected_by_both', 'all')][[\"n_privileged\", \"n_unprivileged\"]].values\n",
    "    ),\n",
    "    columns=[\"n_privileged_model\", \"n_unprivileged_model\"]\n",
    ")\n",
    "\n",
    "\n",
    "bias_calculations = pd.concat([\n",
    "    bias_calculations,\n",
    "    n_model\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unscaled false positives van het model per privileged/unprivileged groep\")\n",
    "pd.DataFrame(\n",
    "    (\n",
    "        bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'afgewezen')][[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"]].values + \n",
    "        bias_dfs[('selected_by_model_not_process_and_in_prepilot', 'niet_afgewezen')][[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"]].values +\n",
    "        bias_dfs[('selected_by_both', 'all')][[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"]].values\n",
    "    ), \n",
    "    columns=[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"], \n",
    "    index=bias_calculations[\"feature\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unscaled false positives van het proces per privileged/unprivileged groep\")\n",
    "pd.DataFrame(\n",
    "    (\n",
    "        bias_dfs[('selected_by_process_not_model', 'all')][[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"]].values +\n",
    "        bias_dfs[('selected_by_both', 'all')][[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"]].values\n",
    "    ), \n",
    "    columns=[\"num_false_positives_privileged\", \"num_false_positives_unprivileged\"], \n",
    "    index=bias_calculations[\"feature\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Percentage geselecteerd van alles door het huidige proces: 7%\")\n",
    "print(f\"Percentage geselecteerd van alles door het model: 14%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bias_results = bias_calculations[[c for c in bias_calculations.columns if (\"ratio\" in c) | (\"diff\" in c) | (\"feature\" in c) | (\"values\" in c) | (\"privileged_model\" in c)]]\n",
    "bias_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geslacht_mapping = {1: \"M\", 2: \"V\"}\n",
    "\n",
    "mappings = {\n",
    "    \"geslacht\": geslacht_mapping,\n",
    "    \"nationaliteit_code_split1\": nationaliteit_mapping,\n",
    "    \"nationaliteit_code_split2\": nationaliteit_mapping,\n",
    "    \"geboorteland_code_split1\": geboorteland_mapping,\n",
    "    \"geboorteland_code_split2\": geboorteland_mapping,\n",
    "    \"burgerlijke_staat_code\": burgerlijke_staat_mapping,\n",
    "}\n",
    "\n",
    "bias_results_mapped = bias_results.copy()\n",
    "\n",
    "for i in [\"privileged_values\", \"unprivileged_values\"]:\n",
    "    for f in [\n",
    "        \"geslacht\",\n",
    "        \"nationaliteit_code_split1\",\n",
    "        \"nationaliteit_code_split2\",\n",
    "        \"geboorteland_code_split1\",\n",
    "        \"geboorteland_code_split2\",\n",
    "        \"burgerlijke_staat_code\",\n",
    "    ]:\n",
    "        print(i, f)\n",
    "        results = list(map(\n",
    "            lambda x: mappings[f][x],\n",
    "            ast.literal_eval(bias_results_mapped.set_index(\"feature\").loc[f, i])\n",
    "        ))\n",
    "        \n",
    "        bias_results_mapped.at[np.where(bias_results_mapped[\"feature\"] == f)[0][0], i] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias_results_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_results_mapped.to_excel(\"20220525_bias_results_bugs_solved.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which features are related to nationality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_analysis_df = data_to_analyze.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_analysis_df[\"nationaliteit_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_analysis_df[\"nationality_west\"] = further_analysis_df[\"nationaliteit_code\"].isin(features_to_check[\"nationaliteit_code_split1\"][0])\n",
    "further_analysis_df[\"nationality_nonwest\"] = further_analysis_df[\"nationaliteit_code\"].isin(features_to_check[\"nationaliteit_code_split1\"][1])\n",
    "\n",
    "further_analysis_df[\"nationality_dutch\"] = further_analysis_df[\"nationaliteit_code\"].isin(features_to_check[\"nationaliteit_code_split2\"][0])\n",
    "further_analysis_df[\"nationality_nondutch\"] = further_analysis_df[\"nationaliteit_code\"].isin(features_to_check[\"nationaliteit_code_split2\"][1])\n",
    "\n",
    "further_analysis_df[\"geboorteland_west\"] = further_analysis_df[\"geboorteland_code\"].isin(features_to_check[\"geboorteland_code_split1\"][0])\n",
    "further_analysis_df[\"geboorteland_nonwest\"] = further_analysis_df[\"geboorteland_code\"].isin(features_to_check[\"geboorteland_code_split1\"][1])\n",
    "\n",
    "further_analysis_df[\"geboorteland_dutch\"] = further_analysis_df[\"geboorteland_code\"].isin(features_to_check[\"geboorteland_code_split2\"][0])\n",
    "further_analysis_df[\"geboorteland_nondutch\"] = further_analysis_df[\"geboorteland_code\"].isin(features_to_check[\"geboorteland_code_split2\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pointbiserialr(tmp_df[group[0]], tmp_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols_to_print = further_analysis_df.columns[:15]  # Only the features\n",
    "\n",
    "correlation_results = []\n",
    "\n",
    "for group in [\n",
    "    (\"nationality_west\", \"nationality_nonwest\"),\n",
    "    (\"nationality_dutch\", \"nationality_nondutch\"),\n",
    "    (\"geboorteland_west\", \"geboorteland_nonwest\"),\n",
    "    (\"geboorteland_dutch\", \"geboorteland_nondutch\"),\n",
    "]:  \n",
    "    means_group0 = further_analysis_df.loc[further_analysis_df[group[0]], cols_to_print].mean()\n",
    "    means_group1 = further_analysis_df.loc[further_analysis_df[group[1]], cols_to_print].mean()\n",
    "    \n",
    "    for i, (m0, m1) in enumerate(zip(means_group0, means_group1)):\n",
    "        tmp_result = {}\n",
    "        tmp_result[\"grouping\"] = group\n",
    "    \n",
    "        feature = means_group0.index[i]\n",
    "    \n",
    "        tmp_df = further_analysis_df[further_analysis_df[group[0]] | further_analysis_df[group[1]]]\n",
    "        corr = scipy.stats.pointbiserialr(tmp_df[group[0]], tmp_df[feature])\n",
    "        \n",
    "        tmp_result[\"feature\"] = feature\n",
    "        tmp_result[\"correlation\"] = f\"{corr.correlation:.3f}\"\n",
    "        tmp_result[\"correlation_p_value\"] = f\"{corr.pvalue:.5f}\"\n",
    "        \n",
    "        tmp_result[\"group0_mean\"] = f\"{m0:.3f}\"\n",
    "        tmp_result[\"group1_mean\"] = f\"{m1:.3f}\"\n",
    "        \n",
    "        correlation_results.append(tmp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_results_df = pd.DataFrame(correlation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_results_df.sort_values([\"grouping\", \"correlation_p_value\"], ascending=True).groupby(\"grouping\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusies:\n",
    "\n",
    "- Nationaliteit\n",
    "    * `nationaliteit_code_split1` betekent westers is privileged, niet-westers is unprivileged.\n",
    "    * `nationaliteit_code_split2` betekent Nederlands is privileged, niet-Nederlands is unprivileged.\n",
    "    * Het model is biased tegen niet-westerse aanvragers, terwijl dat in het proces helemaal niet zo is.\n",
    "    * Krijgen we bij 2 nationaliteiten altijd de niet-westerse nationaliteit? Nee, willekeurig.\n",
    "    * West vs. non-west: Correlatie tussen nationaliteit en features. Wat hebben mensen die niet-westerse nationaliteit hebben en FP zijn met elkaar gemeen?\n",
    "- Vermogen\n",
    "    * `total_vermogen_split1` betekent vermogen >= 0 is privileged, vermogen < 0 is unprivileged.\n",
    "    * `total_vermogen_split2` betekent vermogen > 0 is privileged, vermogen < 0 is unprivileged, dus vermogen = 0 wordt buiten beschouwing gelaten.\n",
    "    * `total_vermogen_split1` heeft in het proces een veel sterkere bias tegenover unprivileged dan `total_vermogen_split2`. Dat duidt er op dat het proces positief kijkt naar aanvragen met nul vermogen. \n",
    "    * `total_vermogen_split2` is waarschijnlijk interessanter om naar te kijken, omdat nul vermogen heel 'straightforward' is, dus minder ruimte voor onderzoekswaardigheid. Terwijl vermogen < 0 schulden zijn en vermogen > 0 betekent dat je misschien boven de vermogensgrens uitkomt.\n",
    "    \n",
    "- Deelnames\n",
    "    * `deelnames_started_percentage_last_year_equals_zero` betekent:\n",
    "        - privileged: mensen die in het afgelopen jaar een of meer deelnames zijn gestart; people who started something or everything\n",
    "        - unprivileged: mensen die in het afgelopen jaar geen enkele deelnames zijn gestart, inclusief de mensen voor wie uberhaupt geen deelnames in het systeem staan; people who started nothing last year (incl. those who weren't in the system last year)\n",
    "    *`deelnames_started_percentage_last_year_equals_one` betekent:\n",
    "        - privileged: mensen die in het afgelopen jaar niet alle deelnames zijn gestart die in het systeem staan of mensen die uberhaupt niet in het systeem voorkwamen; people who didn't start everything or who weren't in the system last year\n",
    "        - unprivileged: mensen die in het afgelopen jaar alle deelnames zijn gestart die in het systeem staan; people who started everything last year\n",
    "        \n",
    "- Partner\n",
    "    * Geen partner is privileged, wel partner is unprivileged.\n",
    "    * Verschil tussen de biases in `has_partner` en `burgerlijke_staat_code`: proces heeft bij burgerlijke staat een bias tegenover singles/gescheiden/weduwen, maar bij partner een bias tegenover mensen met partner > conclusie dat de bias zich vooral tegen ongetrouwde mensen met een partner richt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate FP group size for priv/unpriv and for proces/model.\n",
    "\n",
    "For proces:\n",
    "- Calculate nr. of false positives on everything selected only by proces, or by proces and by model.\n",
    "    * This can be done by simply adding up the FPs for only proces and the FPs for proces and model.\n",
    "- Divide by total number, regardless whether selected or not.\n",
    "\n",
    "For model:\n",
    "- Calculate nr. of false positives on everything selected only by model, or by proces and by model.\n",
    "    * This can be done by adding up the FPs for only proces and the FPs for proces and model.\n",
    "    * First have to calculate the FPs for only proces. We should scale them to represent the fraction of afgewezen/niet-afgewezen in the whole dataset, because the fraction afgewezen/niet-afgewezen is different in the only-proces sample.\n",
    "- Divide by total number, regardless whether selected or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print info about the metrics\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(BiasAnalyzer.log_info_by_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run the stuff below\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- False discovery rate difference is positive (0.011), meaning that the female group is (barely) disadvantaged.\n",
    "- False positive rate difference is negative (-0.089), meaning that the male group is disadvantaged.\n",
    "- False positive/group size difference is negative (-0.054), meaning that the male group is disadvantaged.\n",
    "\n",
    "#### False discovery rate difference interpretation\n",
    "FDR male = 0.1\n",
    "Out of all the males we investigate, 10% are actually innocent.\n",
    "\n",
    "FDR female = 0.1 + 0.011 = 0.111\n",
    "Out of all the females we investigate, 11.1% are actually innocent.\n",
    "\n",
    "If we investigate a woman, she is 1.1 percentage points more likely to be innocent than a man we investigate.\n",
    "\n",
    "\n",
    "#### False positive rate difference interpretation\n",
    "FPR male = 0.1\n",
    "If you are an innocent male, then you have a 10% chance of being investigated anyway.\n",
    "\n",
    "FPR female = 0.1 - 0.089 = 0.011\n",
    "If you are an innocent female, then you have a 1.1% chance of being investigated anyway.\n",
    "\n",
    "The chance of being investigated as an innocent male is 8.9 percentage points higher than as an innocent female.\n",
    "\n",
    "\n",
    "#### False positive/group size difference interpretation\n",
    "FP/GS male = 0.089\n",
    "A random man has a 8.9% chance to be wrongly investigated.\n",
    "\n",
    "FP/GS female = 0.035\n",
    "A random woman has a 3.5% chance to be wrongly investigated.\n",
    "\n",
    "The chance of being wrongly investigated for a random man is 5.4 percentage points higher than for a random woman."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
