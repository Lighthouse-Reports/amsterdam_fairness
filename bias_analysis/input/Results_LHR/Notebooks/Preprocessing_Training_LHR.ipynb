{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "\n",
    "# To display BSNs fully\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "\n",
    "# For convenience\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wpi_uitkeringsfraude.project_paths import ARTIFACT_PATH, DATA_PATH, CONFIG_PATH, INFO_PATH\n",
    "from wpi_uitkeringsfraude.model.manage_model_info import load_feature_list\n",
    "# from wpi_uitkeringsfraude.model.build_model import filter_application_handling\n",
    "from wpi_uitkeringsfraude.settings.settings import WPISettings\n",
    "# from wpi_uitkeringsfraude.components import SocratesDienstPersoonJoin, SocratesAdresFeatures\n",
    "from wpi_uitkeringsfraude.scorer import Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the entire dataset of the period of the training data (excluding necessary filters)\n",
    "df = pd.read_parquet(\"\\data\\training\\transformed_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know from documentation that the final dataset is around 3400 applications with about 55% positive label\n",
    "# So we can be relatively certain this is indeed the final training dataset\n",
    "display(df.loc[df['is_onderzoek_hh'] == 1, 'onderzoekswaardig'].value_counts())\n",
    "print(1860/(1860+1538))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we extract the training data from the full dataset\n",
    "df_training = df.loc[df['is_onderzoek_hh'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Slimme Check Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "\n",
    "df_training = df_training.sort_values(by='subjectnr')\n",
    "\n",
    "X = df_training.loc[:, df_training.columns != 'onderzoekswaardig']\n",
    "y = df_training['onderzoekswaardig']\n",
    "\n",
    "seed = 42\n",
    "# np.random.seed(seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model_file_prepilot = Path('\\Models\\20220523_model_used_in_prepilot.pkl')\n",
    "model_file_pilot = Path('\\Models\\20240228_wpi_model_pilot_31.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "models = {'model_before_reweighing':model_file_prepilot,\n",
    "          'model_after_reweighing': model_file_pilot}\n",
    "# Set threshold\n",
    "thr=0.63\n",
    "\n",
    "for model_name, model_file in models.items():\n",
    "    model_dict = joblib.load(model_file)\n",
    "    model = model_dict[\"model\"]\n",
    "    prep = model[:-1]  # all but the last pipeline steps, hence all transformers, but not the model\n",
    "    clf = model[-1]  # the actual model\n",
    "    num_cols, cat_cols = load_feature_list()\n",
    "    label = \"onderzoekswaardig\"\n",
    "    # Model scores\n",
    "    X_test[f\"{model_name}_score\"] = model.predict_proba(X_test)[:,1]\n",
    "    # Check if above threshold\n",
    "    X_test[f\"{model_name}_prediction\"] = (model.predict_proba(X_test)[:, 1] >= thr).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "models = {'model_before_reweighing':model_file_prepilot,\n",
    "          'model_after_reweighing': model_file_pilot}\n",
    "\n",
    "\n",
    "for model_name, model_file in models.items():\n",
    "    model_dict = joblib.load(model_file)\n",
    "    model = model_dict[\"model\"]\n",
    "    prep = model[:-1]  # all but the last pipeline steps, hence all transformers, but not the model\n",
    "    clf = model[-1]  # the actual model\n",
    "    num_cols, cat_cols = load_feature_list()\n",
    "    label = \"onderzoekswaardig\"\n",
    "    # Model scores\n",
    "    X_train[f\"{model_name}_score\"] = model.predict_proba(X_train)[:,1]\n",
    "    # Check if above threshold\n",
    "    X_train[f\"{model_name}_prediction\"] = (model.predict_proba(X_train)[:, 1] >= thr).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['onderzoekswaardig'] = y_train\n",
    "X_test['onderzoekswaardig'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "\n",
    "conf_before_reweigh = confusion_matrix(X_test['onderzoekswaardig'], X_test['model_before_reweighing_prediction'])\n",
    "conf_after_reweigh = confusion_matrix(X_test['onderzoekswaardig'], X_test['model_after_reweighing_prediction'])\n",
    "\n",
    "print(\"Conf matrix before reweighing\")\n",
    "print(conf_before_reweigh)\n",
    "\n",
    "print(\"Conf matrix after reweighing\")\n",
    "print(conf_after_reweigh)\n",
    "\n",
    "print()\n",
    "print(\"Precision before reweighing\")\n",
    "# display(conf_before_reweigh[0,0]/(conf_before_reweigh[0,0]+conf_before_reweigh[0,1]))\n",
    "print(precision_score(X_test['onderzoekswaardig'], X_test['model_before_reweighing_prediction']))\n",
    "\n",
    "\n",
    "print(\"Precision after reweighing\")\n",
    "print(precision_score(X_test['onderzoekswaardig'], X_test['model_after_reweighing_prediction']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_before_reweigh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process for bias analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['dataset'] = 'Training_train'\n",
    "X_test['dataset'] = 'Training_test'\n",
    "df_training = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need certain columns for the bias analysis\n",
    "columns_filter_training  = ['application_dienstnr', 'dtaanvraag', 'onderzoekswaardig', 'model_before_reweighing_score', 'model_before_reweighing_prediction',\n",
    "                            'model_after_reweighing_score', 'model_after_reweighing_prediction']\n",
    "\n",
    "df_training_interim = df_training[columns_filter_training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_training_interim = df_training_interim.rename(columns = {'application_dienstnr':'dienstnr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_verrijking = ['application_dienstnr', 'dtaanvraag']\n",
    "df_training_interim_verrijking = df_training_interim[columns_verrijking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_interim_verrijking.to_csv(\"20240111_training_data_verrijking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge enriched data and training data for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_bias = df_training[['application_dienstnr', 'received_same_product_last_year',\n",
    "       'applied_for_same_product_last_year', 'days_since_last_dienst_end',\n",
    "       'days_since_last_relocation', 'active_address_count', 'dtaanvraag',\n",
    "       'is_parttime_parent', 'is_fulltime_parent',\n",
    "       'model_before_reweighing_score', 'model_before_reweighing_prediction',\n",
    "       'model_after_reweighing_score', 'model_after_reweighing_prediction',\n",
    "       'onderzoekswaardig', 'dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still need to add nationality from enriched_dataset\n",
    "df_enriched = pd.read_excel(\"\\data\\interim_data\\Enrichment_files\\20240201_Enriched_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched_training = df_enriched.loc[df_enriched['LABELDATA'] == 'training']\n",
    "df_enriched_training = df_enriched_training[['DIENSTNR', 'DTGEBOORTE','NATIONALITEIT1','NATIONALITEIT1_OMSCHRIJVING', 'GESLACHT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_bias['application_dienstnr'] = df_training_bias['application_dienstnr'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_bias = pd.merge(df_training_bias, df_enriched_training, left_on='application_dienstnr', right_on = 'DIENSTNR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_bias['onderzoekswaardig'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age and store the result in a new column 'Leeftijd'\n",
    "df_training_bias['Leeftijd'] = np.floor((df_training_bias['dtaanvraag'] - df_training_bias['DTGEBOORTE']) / np.timedelta64(1, 'Y'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_bias.to_excel(\"\\data\\processed_bias_data\\20240131_training_processed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_bias['GESLACHT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
